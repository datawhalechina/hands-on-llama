{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a43286b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import struct\n",
    "import inspect\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    # default hyperparameters for the Llama 7B model\n",
    "    dim: int = 4\n",
    "    n_layers: int = 4\n",
    "    n_heads: int = 1\n",
    "    n_kv_heads: Optional[int] = None\n",
    "    vocab_size: int = 1024\n",
    "    hidden_dim: Optional[int] = None\n",
    "    multiple_of: int = 8\n",
    "    norm_eps: float = 1e-5\n",
    "    max_seq_len: int = 1024\n",
    "    dropout: float = 0.0\n",
    "    max_batch_size: int = 1\n",
    "\n",
    "\n",
    "\n",
    "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)  # type: ignore\n",
    "    freqs = torch.outer(t, freqs).float()  # type: ignore\n",
    "    freqs_cos = torch.cos(freqs)  # real part\n",
    "    freqs_sin = torch.sin(freqs)  # imaginary part\n",
    "    return freqs_cos, freqs_sin\n",
    "\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "    ndim = x.ndim\n",
    "    assert 0 <= 1 < ndim\n",
    "    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
    "    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "    return freqs_cis.view(shape)\n",
    "\n",
    "\n",
    "def apply_rotary_emb(\n",
    "    xq: torch.Tensor,\n",
    "    xk: torch.Tensor,\n",
    "    freqs_cos: torch.Tensor,\n",
    "    freqs_sin: torch.Tensor\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "\n",
    "    # reshape xq and xk to match the complex representation\n",
    "    xq_r, xq_i = xq.float().reshape(xq.shape[:-1] + (-1, 2)).unbind(-1)\n",
    "    xk_r, xk_i = xk.float().reshape(xk.shape[:-1] + (-1, 2)).unbind(-1)\n",
    "\n",
    "    # reshape freqs_cos and freqs_sin for broadcasting\n",
    "    freqs_cos = reshape_for_broadcast(freqs_cos, xq_r)\n",
    "    freqs_sin = reshape_for_broadcast(freqs_sin, xq_r)\n",
    "\n",
    "    # apply rotation using real numbers\n",
    "    xq_out_r = xq_r * freqs_cos - xq_i * freqs_sin\n",
    "    xq_out_i = xq_r * freqs_sin + xq_i * freqs_cos\n",
    "    xk_out_r = xk_r * freqs_cos - xk_i * freqs_sin\n",
    "    xk_out_i = xk_r * freqs_sin + xk_i * freqs_cos\n",
    "\n",
    "    # flatten last two dimensions\n",
    "    xq_out = torch.stack([xq_out_r, xq_out_i], dim=-1).flatten(3)\n",
    "    xk_out = torch.stack([xk_out_r, xk_out_i], dim=-1).flatten(3)\n",
    "\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
    "\n",
    "\n",
    "\n",
    "def repeat_kv(x: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
    "    \"\"\"torch.repeat_interleave(x, dim=2, repeats=n_rep)\"\"\"\n",
    "    bs, slen, n_kv_heads, head_dim = x.shape\n",
    "    if n_rep == 1:\n",
    "        return x\n",
    "    return (\n",
    "        x[:, :, :, None, :]\n",
    "        .expand(bs, slen, n_kv_heads, n_rep, head_dim)\n",
    "        .reshape(bs, slen, n_kv_heads * n_rep, head_dim)\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, args: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.n_kv_heads = args.n_heads if args.n_kv_heads is None else args.n_kv_heads\n",
    "        assert args.n_heads % self.n_kv_heads == 0\n",
    "        model_parallel_size = 1\n",
    "        self.n_local_heads = args.n_heads // model_parallel_size\n",
    "        self.n_local_kv_heads = self.n_kv_heads // model_parallel_size\n",
    "        self.n_rep = self.n_local_heads // self.n_local_kv_heads\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "        self.wq = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wk = nn.Linear(args.dim, self.n_kv_heads * self.head_dim, bias=False)\n",
    "        self.wv = nn.Linear(args.dim, self.n_kv_heads * self.head_dim, bias=False)\n",
    "        self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim, bias=False)\n",
    "        self.attn_dropout = nn.Dropout(args.dropout)\n",
    "        self.resid_dropout = nn.Dropout(args.dropout)\n",
    "        self.dropout = args.dropout\n",
    "        \n",
    "        mask = torch.full((1, 1, args.max_seq_len, args.max_seq_len), float(\"-inf\"))\n",
    "        mask = torch.triu(mask, diagonal=1)\n",
    "        self.register_buffer(\"mask\", mask)\n",
    "        \n",
    "        self.cache_k = torch.zeros(\n",
    "            (\n",
    "                args.max_batch_size,\n",
    "                args.max_seq_len,\n",
    "                self.n_kv_heads,\n",
    "                self.head_dim,\n",
    "            )\n",
    "        )\n",
    "        self.cache_v = torch.zeros(\n",
    "            (\n",
    "                args.max_batch_size,\n",
    "                args.max_seq_len,\n",
    "                self.n_kv_heads,\n",
    "                self.head_dim,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        freqs_cos: torch.Tensor,\n",
    "        freqs_sin: torch.Tensor,\n",
    "        start_pos: torch.Tensor,\n",
    "        use_cache: bool = True\n",
    "    ):\n",
    "        bsz, seqlen, _ = x.shape\n",
    "\n",
    "        # QKV\n",
    "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
    "        xq = xq.view(bsz, seqlen, self.n_local_heads, self.head_dim)\n",
    "        xk = xk.view(bsz, seqlen, self.n_local_kv_heads, self.head_dim)\n",
    "        xv = xv.view(bsz, seqlen, self.n_local_kv_heads, self.head_dim)\n",
    "\n",
    "        # RoPE relative positional embeddings\n",
    "        xq, xk = apply_rotary_emb(xq, xk, freqs_cos, freqs_sin)\n",
    "        \n",
    "        if use_cache:\n",
    "            self.cache_k[:bsz, start_pos : start_pos + seqlen] = xk\n",
    "            self.cache_v[:bsz, start_pos : start_pos + seqlen] = xv\n",
    "\n",
    "            ks = self.cache_k[:bsz, : start_pos + seqlen]\n",
    "            vs = self.cache_v[:bsz, : start_pos + seqlen]\n",
    "        else:\n",
    "            ks = xk\n",
    "            vs = xv\n",
    "        \n",
    "        # grouped multiquery attention: expand out keys and values\n",
    "        xk = repeat_kv(ks, self.n_rep)  # (bs, seqlen, n_local_heads, head_dim)\n",
    "        xv = repeat_kv(vs, self.n_rep)  # (bs, seqlen, n_local_heads, head_dim)\n",
    "\n",
    "        # make heads into a batch dimension\n",
    "        xq = xq.transpose(1, 2)  # (bs, n_local_heads, seqlen, head_dim)\n",
    "        xk = xk.transpose(1, 2)\n",
    "        xv = xv.transpose(1, 2)\n",
    "        \n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html\n",
    "#         mask = self.mask[0, 0, :seqlen, :seqlen]\n",
    "#         output = torch.nn.functional.scaled_dot_product_attention(\n",
    "#             xq, xk, xv, attn_mask=mask, dropout_p=self.dropout if self.training else 0.0\n",
    "#         )\n",
    "        \n",
    "        scores = torch.matmul(xq, xk.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "        scores = scores + self.mask[:, :, :seqlen, :seqlen]   # (bs, n_local_heads, seqlen, cache_len + seqlen)\n",
    "        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
    "        scores = self.attn_dropout(scores)\n",
    "        output = torch.matmul(scores, xv)\n",
    "        \n",
    "        # restore time as batch dimension and concat heads\n",
    "        output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1)\n",
    "\n",
    "        # final projection into the residual stream\n",
    "        output = self.wo(output)\n",
    "        output = self.resid_dropout(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d5637f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdab2e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "593867cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ModelArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9375fb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 2]), torch.Size([1024, 2]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs_cos, freqs_sin = precompute_freqs_cis(params.dim // params.n_heads, params.max_seq_len)\n",
    "freqs_cos.shape, freqs_sin.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9501e8",
   "metadata": {},
   "source": [
    "## Context+Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd0a1718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2590,  0.3917, -0.2154, -0.1412],\n",
       "         [-0.2325,  0.3910, -0.2234, -0.1140],\n",
       "         [-0.1691,  0.1946, -0.0948, -0.1264],\n",
       "         [-0.1622,  0.1424, -0.0596, -0.1409],\n",
       "         [-0.1475,  0.1171, -0.0438, -0.1316]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KV Cache发生的地方就在Attention\n",
    "model = Attention(params)\n",
    "torch.manual_seed(42)\n",
    "x = torch.rand(1, 5, 4) # bs, seq_len, dim\n",
    "model(x, freqs_cos[:5], freqs_sin[:5], 0, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb105fdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3081, -0.2316, -0.5535, -0.3219,  0.1441,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KV Cache已被填充，L=5个\n",
    "model.cache_k[0, :10, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad56519a",
   "metadata": {},
   "source": [
    "## Context+Current+Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f674d66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2590,  0.3917, -0.2154, -0.1412],\n",
       "         [-0.2325,  0.3910, -0.2234, -0.1140],\n",
       "         [-0.1691,  0.1946, -0.0948, -0.1264],\n",
       "         [-0.1622,  0.1424, -0.0596, -0.1409]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这一轮先生成4个\n",
    "model = Attention(params)\n",
    "torch.manual_seed(42)\n",
    "x = torch.rand(1, 5, 4)\n",
    "x1 = x[:, :4, :]\n",
    "x2 = x[:, 4:5, :]\n",
    "model(x1, freqs_cos[:4], freqs_sin[:4], 0, True)\n",
    "# 注意看，这个输出和刚刚的前4个是一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f4f407a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3081, -0.2316, -0.5535, -0.3219,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 看新的KV Cache，和前面的前4个依然是一样的\n",
    "model.cache_k[0, :10, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8182f4a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1475,  0.1171, -0.0438, -0.1316]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 然后我们生成第5个Token，生成的就是最开始的第5行\n",
    "model(x2, freqs_cos[4:5], freqs_sin[4:5], 4, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c93d3f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3081, -0.2316, -0.5535, -0.3219,  0.1441,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 再来看KV Cache，第5个元素来了！\n",
    "model.cache_k[0, :10, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fb9c84",
   "metadata": {},
   "source": [
    "## Context+NoCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8a8e173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2590,  0.3917, -0.2154, -0.1412],\n",
       "         [-0.2325,  0.3910, -0.2234, -0.1140],\n",
       "         [-0.1691,  0.1946, -0.0948, -0.1264],\n",
       "         [-0.1622,  0.1424, -0.0596, -0.1409],\n",
       "         [-0.1475,  0.1171, -0.0438, -0.1316]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 现在不使用KV Cache\n",
    "model = Attention(params)\n",
    "torch.manual_seed(42)\n",
    "x = torch.rand(1, 5, 4)\n",
    "model(x, freqs_cos[:5], freqs_sin[:5], 0, False)\n",
    "# 结果和使用了Cache是一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "866c2cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cache没有\n",
    "model.cache_k[0, :10, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c28b6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab8247c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b00227",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
